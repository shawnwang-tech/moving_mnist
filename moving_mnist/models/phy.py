# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/03_phy.ipynb (unless otherwise specified).

__all__ = ['PhyCell_Cell', 'PhyCell']

# Cell
from fastai.vision.all import *

# Cell
class PhyCell_Cell(Module):
    def __init__(self, ch_in, hidden_dim, ks=3, bias=True):
        store_attr()
        padding = ks // 2
        bias = bias
        self.f = nn.Sequential(
                 nn.BatchNorm2d(ch_in),
                 nn.Conv2d(ch_in, hidden_dim, ks, padding=padding),
                 nn.Conv2d(hidden_dim, ch_in, kernel_size=(1,1)))

        self.convgate = nn.Conv2d(2*ch_in,
                                  ch_in,
                                  kernel_size=(3,3),
                                  padding=(1,1),
                                  bias=bias)

    def forward(self, x, hidden=None):
        "x ~[batch_size, hidden_dim, height, width]"
        if hidden is None: hidden = self.init_hidden(x)
        hidden_tilde = hidden + self.f(hidden)
        combined = torch.cat([x, hidden_tilde], dim=1)
        combined_conv = self.convgate(combined)
        K = torch.sigmoid(combined_conv)
        next_hidden = hidden_tilde + K * (x - hidden_tilde)
        return next_hidden

    def init_hidden(self, x):
        bs, ch, h, w = x.shape
        return one_param(self).new_zeros(bs, ch, h, w)

# Cell
class PhyCell(Module):
    def __init__(self, ch_in, hidden_dims, ks, n_layers):
        store_attr()
        self.cell_list = nn.ModuleList()
        for i in range(self.n_layers):
            self.cell_list.append(PhyCell_Cell(ch_in=ch_in,
                                               hidden_dim=hidden_dims[i],
                                               ks=ks))

    def forward(self, x, hidden=None):
        "x ~ [batch_size, seq_len, channels, width, height]"
        assert x.shape[2] == self.ch_in, "Input tensor has different channels dim than Cell"
        if hidden is None: hidden = self.init_hidden(x)
        cur_layer_input = torch.unbind(x, dim=1)
        seq_len = len(cur_layer_input)
        last_state_list = []

        for cell, h in zip(self.cell_list, hidden):
            output_inner = []
            for inp in cur_layer_input:
                h = cell(inp, h)
                output_inner.append(h)
            cur_layer_input = output_inner
            last_state_list.append(h)

        layer_output = torch.stack(output_inner, dim=1)
        last_states = torch.stack(last_state_list, dim=0)
        return layer_output, last_states

    def init_hidden(self, x):
        assert len(x.shape)==5, "input shape must be [bs, seq_len, ch, w, h]"
        hid = []
        for l in self.cell_list:
            hid.append(l.init_hidden(x[:,0, ...]))
        return hid