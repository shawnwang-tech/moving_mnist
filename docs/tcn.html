---

title: Temporal convnets


keywords: fastai
sidebar: home_sidebar

summary: "TCN on 3D"
description: "TCN on 3D"
nb_path: "nbs/02_tcn.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs/02_tcn.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">set_device</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">get_device_name</span><span class="p">())</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>GeForce RTX 2070 SUPER
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="VGG-Image-Encoder:">VGG Image Encoder:<a class="anchor-link" href="#VGG-Image-Encoder:"> </a></h2>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="VGGBlock" class="doc_header"><code>class</code> <code>VGGBlock</code><a href="https://github.com/tcapelle/moving_mnist/tree/master/moving_mnist/models/tcn.py#L11" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>VGGBlock</code>(<strong><code>ni</code></strong>, <strong><code>nf</code></strong>, <strong><code>ks</code></strong>=<em><code>3</code></em>, <strong><code>pool</code></strong>=<em><code>True</code></em>, <strong><code>conv_cls</code></strong>=<em><code>Conv2d</code></em>, <strong><code>act</code></strong>=<em><code>ReLU()</code></em>, <strong><code>xtra</code></strong>=<em><code>None</code></em>) :: <code>Sequential</code></p>
</blockquote>
<p>A sequential container.
Modules will be added to it in the order they are passed in the constructor.
Alternatively, an ordered dict of modules can also be passed in.</p>
<p>To make it easier to understand, here is a small example::</p>

<pre><code># Example of using Sequential
model = nn.Sequential(
          nn.Conv2d(1,20,5),
          nn.ReLU(),
          nn.Conv2d(20,64,5),
          nn.ReLU()
        )

# Example of using Sequential with OrderedDict
model = nn.Sequential(OrderedDict([
          ('conv1', nn.Conv2d(1,20,5)),
          ('relu1', nn.ReLU()),
          ('conv2', nn.Conv2d(20,64,5)),
          ('relu2', nn.ReLU())
        ]))</code></pre>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">VGGBlock</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">64</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>VGGBlock(
  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (2): ReLU()
  (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="VGG" class="doc_header"><code>class</code> <code>VGG</code><a href="https://github.com/tcapelle/moving_mnist/tree/master/moving_mnist/models/tcn.py#L20" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>VGG</code>(<strong><code>n_in</code></strong>=<em><code>3</code></em>, <strong><code>layers</code></strong>=<em><code>[1, 1, 2]</code></em>, <strong><code>ks</code></strong>=<em><code>3</code></em>, <strong><code>conv_cls</code></strong>=<em><code>Conv2d</code></em>, <strong><code>act</code></strong>=<em><code>ReLU()</code></em>, <strong><code>ni</code></strong>=<em><code>64</code></em>, <strong><code>last_pool</code></strong>=<em><code>False</code></em>, <strong><code>self_attention</code></strong>=<em><code>False</code></em>) :: <code>Module</code></p>
</blockquote>
<p>VGG Net <a href="https://neurohive.io/en/popular-networks/vgg16/">https://neurohive.io/en/popular-networks/vgg16/</a></p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's use the <a href="/moving_mnist/models.conv_rnn.html#TimeDistributed"><code>TimeDistributed</code></a> layer to accept a image sequence:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">small_vgg</span> <span class="o">=</span> <span class="n">VGG</span><span class="p">()</span>
<span class="n">small_vgg</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>VGG(
  (image_encoder): Sequential(
    (0): VGGBlock(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (1): VGGBlock(
      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (2): VGGBlock(
      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (3): VGGBlock(
      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
    (4): VGGBlock(
      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
  )
)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">small_vgg</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">128</span><span class="p">,</span><span class="mi">128</span><span class="p">))</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>torch.Size([2, 256, 16, 16])</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="3d-TCN">3d TCN<a class="anchor-link" href="#3d-TCN"> </a></h2>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="Chomp1d" class="doc_header"><code>class</code> <code>Chomp1d</code><a href="https://github.com/tcapelle/moving_mnist/tree/master/moving_mnist/models/tcn.py#L35" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>Chomp1d</code>(<strong><code>chomp_size</code></strong>, <strong><code>tdim</code></strong>=<em><code>2</code></em>) :: <code>Module</code></p>
</blockquote>
<p>Same as <code>nn.Module</code>, but no need for subclasses to call <code>super().__init__</code></p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="TemporalBlock3D" class="doc_header"><code>class</code> <code>TemporalBlock3D</code><a href="https://github.com/tcapelle/moving_mnist/tree/master/moving_mnist/models/tcn.py#L49" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>TemporalBlock3D</code>(<strong><code>n_in</code></strong>, <strong><code>n_out</code></strong>, <strong><code>ks</code></strong>, <strong><code>stride</code></strong>=<em><code>1</code></em>, <strong><code>dilation</code></strong>=<em><code>2</code></em>, <strong><code>dropout</code></strong>=<em><code>0.2</code></em>) :: <code>Module</code></p>
</blockquote>
<p>A resnet type temporal Block</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">ks</span><span class="o">=</span><span class="mi">2</span>
<span class="n">dilation</span><span class="o">=</span><span class="mi">2</span>
<span class="n">stride</span><span class="o">=</span><span class="mi">1</span>

<span class="n">tb</span> <span class="o">=</span> <span class="n">TemporalBlock3D</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">ks</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">dilation</span><span class="p">)</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tb</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>TemporalBlock3D(
  (conv1): Conv3d(128, 64, kernel_size=(2, 3, 3), stride=(1, 1, 1), padding=(2, 1, 1), dilation=(2, 1, 1))
  (chomp1): Chomp(2)
  (relu1): ReLU()
  (dropout1): Dropout(p=0.2, inplace=False)
  (conv2): Conv3d(64, 64, kernel_size=(2, 3, 3), stride=(1, 1, 1), padding=(2, 1, 1), dilation=(2, 1, 1))
  (chomp2): Chomp(2)
  (relu2): ReLU()
  (dropout2): Dropout(p=0.2, inplace=False)
  (net): Sequential(
    (0): Conv3d(128, 64, kernel_size=(2, 3, 3), stride=(1, 1, 1), padding=(2, 1, 1), dilation=(2, 1, 1))
    (1): Chomp(2)
    (2): ReLU()
    (3): Dropout(p=0.2, inplace=False)
    (4): Conv3d(64, 64, kernel_size=(2, 3, 3), stride=(1, 1, 1), padding=(2, 1, 1), dilation=(2, 1, 1))
    (5): Chomp(2)
    (6): ReLU()
    (7): Dropout(p=0.2, inplace=False)
  )
  (downsample): Conv3d(128, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))
  (relu): ReLU()
)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tb</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span><span class="o">.</span><span class="n">cuda</span><span class="p">())</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>torch.Size([2, 64, 30, 32, 32])</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="TemporalConvNet3D" class="doc_header"><code>class</code> <code>TemporalConvNet3D</code><a href="https://github.com/tcapelle/moving_mnist/tree/master/moving_mnist/models/tcn.py#L86" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>TemporalConvNet3D</code>(<strong><code>num_inputs</code></strong>, <strong><code>num_channels</code></strong>, <strong><code>ks</code></strong>=<em><code>3</code></em>, <strong><code>dropout</code></strong>=<em><code>0.2</code></em>) :: <code>Module</code></p>
</blockquote>
<p>Same as <code>nn.Module</code>, but no need for subclasses to call <code>super().__init__</code></p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tc</span> <span class="o">=</span> <span class="n">TemporalConvNet3D</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="p">[</span><span class="mi">64</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tc</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span><span class="o">.</span><span class="n">cuda</span><span class="p">())</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>torch.Size([2, 1, 30, 32, 32])</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="TCN3D" class="doc_header"><code>class</code> <code>TCN3D</code><a href="https://github.com/tcapelle/moving_mnist/tree/master/moving_mnist/models/tcn.py#L103" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>TCN3D</code>(<strong><code>input_size</code></strong>, <strong><code>num_channels</code></strong>, <strong><code>kernel_size</code></strong>=<em><code>3</code></em>, <strong><code>p</code></strong>=<em><code>0.2</code></em>) :: <code>Module</code></p>
</blockquote>
<p>Same as <code>nn.Module</code>, but no need for subclasses to call <code>super().__init__</code></p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tcn</span> <span class="o">=</span> <span class="n">TCN3D</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="p">[</span><span class="mi">32</span><span class="p">,</span> <span class="mi">16</span><span class="p">])</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tcn</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span><span class="o">.</span><span class="n">cuda</span><span class="p">())</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>torch.Size([2, 30, 16, 16, 16])</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>A very hardcoded TCN to make some test, will refactor on modular later on,</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="SimpleTCN" class="doc_header"><code>class</code> <code>SimpleTCN</code><a href="https://github.com/tcapelle/moving_mnist/tree/master/moving_mnist/models/tcn.py#L112" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>SimpleTCN</code>(<strong><code>n_in</code></strong>=<em><code>1</code></em>, <strong><code>ks</code></strong>=<em><code>3</code></em>, <strong><code>n_out</code></strong>=<em><code>1</code></em>, <strong><code>norm</code></strong>=<em><code>&lt;NormType.Batch: 1&gt;</code></em>, <strong><code>dilation</code></strong>=<em><code>2</code></em>, <strong><code>debug</code></strong>=<em><code>False</code></em>) :: <code>Module</code></p>
</blockquote>
<p>Simple TCN model</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">stcn</span> <span class="o">=</span> <span class="n">SimpleTCN</span><span class="p">()</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">stcn</span><span class="o">.</span><span class="n">summary</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">)</span><span class="o">.</span><span class="n">cuda</span><span class="p">())</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>SimpleTCN (Input shape: [&#39;2 x 1 x 10 x 64 x 64&#39;])
================================================================
Layer (type)         Output Shape         Param #    Trainable 
================================================================
AddCoords            2 x 4 x 64 x 64      0          False     
________________________________________________________________
Conv2d               2 x 8 x 64 x 64      40         True      
________________________________________________________________
Conv2d               2 x 16 x 32 x 32     1,152      True      
________________________________________________________________
BatchNorm2d          2 x 16 x 32 x 32     32         True      
________________________________________________________________
ReLU                 2 x 16 x 32 x 32     0          False     
________________________________________________________________
Conv3d               2 x 16 x 12 x 32 x   4,640      True      
________________________________________________________________
Chomp1d              2 x 16 x 10 x 32 x   0          False     
________________________________________________________________
ReLU                 2 x 16 x 10 x 32 x   0          False     
________________________________________________________________
Dropout              2 x 16 x 10 x 32 x   0          False     
________________________________________________________________
Conv3d               2 x 16 x 12 x 32 x   4,640      True      
________________________________________________________________
Chomp1d              2 x 16 x 10 x 32 x   0          False     
________________________________________________________________
ReLU                 2 x 16 x 10 x 32 x   0          False     
________________________________________________________________
Dropout              2 x 16 x 10 x 32 x   0          False     
________________________________________________________________
Conv3d               2 x 16 x 12 x 32 x   4,640      True      
________________________________________________________________
Chomp1d              2 x 16 x 10 x 32 x   0          False     
________________________________________________________________
ReLU                 2 x 16 x 10 x 32 x   0          False     
________________________________________________________________
Dropout              2 x 16 x 10 x 32 x   0          False     
________________________________________________________________
Conv3d               2 x 16 x 12 x 32 x   4,640      True      
________________________________________________________________
Chomp1d              2 x 16 x 10 x 32 x   0          False     
________________________________________________________________
ReLU                 2 x 16 x 10 x 32 x   0          False     
________________________________________________________________
Dropout              2 x 16 x 10 x 32 x   0          False     
________________________________________________________________
ReLU                 2 x 16 x 10 x 32 x   0          False     
________________________________________________________________
Conv2d               2 x 32 x 16 x 16     4,608      True      
________________________________________________________________
BatchNorm2d          2 x 32 x 16 x 16     64         True      
________________________________________________________________
ReLU                 2 x 32 x 16 x 16     0          False     
________________________________________________________________
Conv3d               2 x 32 x 12 x 16 x   18,496     True      
________________________________________________________________
Chomp1d              2 x 32 x 10 x 16 x   0          False     
________________________________________________________________
ReLU                 2 x 32 x 10 x 16 x   0          False     
________________________________________________________________
Dropout              2 x 32 x 10 x 16 x   0          False     
________________________________________________________________
Conv3d               2 x 32 x 12 x 16 x   18,496     True      
________________________________________________________________
Chomp1d              2 x 32 x 10 x 16 x   0          False     
________________________________________________________________
ReLU                 2 x 32 x 10 x 16 x   0          False     
________________________________________________________________
Dropout              2 x 32 x 10 x 16 x   0          False     
________________________________________________________________
Conv3d               2 x 32 x 12 x 16 x   18,496     True      
________________________________________________________________
Chomp1d              2 x 32 x 10 x 16 x   0          False     
________________________________________________________________
ReLU                 2 x 32 x 10 x 16 x   0          False     
________________________________________________________________
Dropout              2 x 32 x 10 x 16 x   0          False     
________________________________________________________________
Conv3d               2 x 32 x 12 x 16 x   18,496     True      
________________________________________________________________
Chomp1d              2 x 32 x 10 x 16 x   0          False     
________________________________________________________________
ReLU                 2 x 32 x 10 x 16 x   0          False     
________________________________________________________________
Dropout              2 x 32 x 10 x 16 x   0          False     
________________________________________________________________
ReLU                 2 x 32 x 10 x 16 x   0          False     
________________________________________________________________
Conv2d               2 x 64 x 8 x 8       18,432     True      
________________________________________________________________
BatchNorm2d          2 x 64 x 8 x 8       128        True      
________________________________________________________________
ReLU                 2 x 64 x 8 x 8       0          False     
________________________________________________________________
Conv3d               2 x 64 x 12 x 8 x 8  73,856     True      
________________________________________________________________
Chomp1d              2 x 64 x 10 x 8 x 8  0          False     
________________________________________________________________
ReLU                 2 x 64 x 10 x 8 x 8  0          False     
________________________________________________________________
Dropout              2 x 64 x 10 x 8 x 8  0          False     
________________________________________________________________
Conv3d               2 x 64 x 12 x 8 x 8  73,856     True      
________________________________________________________________
Chomp1d              2 x 64 x 10 x 8 x 8  0          False     
________________________________________________________________
ReLU                 2 x 64 x 10 x 8 x 8  0          False     
________________________________________________________________
Dropout              2 x 64 x 10 x 8 x 8  0          False     
________________________________________________________________
Conv3d               2 x 64 x 12 x 8 x 8  73,856     True      
________________________________________________________________
Chomp1d              2 x 64 x 10 x 8 x 8  0          False     
________________________________________________________________
ReLU                 2 x 64 x 10 x 8 x 8  0          False     
________________________________________________________________
Dropout              2 x 64 x 10 x 8 x 8  0          False     
________________________________________________________________
Conv3d               2 x 64 x 12 x 8 x 8  73,856     True      
________________________________________________________________
Chomp1d              2 x 64 x 10 x 8 x 8  0          False     
________________________________________________________________
ReLU                 2 x 64 x 10 x 8 x 8  0          False     
________________________________________________________________
Dropout              2 x 64 x 10 x 8 x 8  0          False     
________________________________________________________________
ReLU                 2 x 64 x 10 x 8 x 8  0          False     
________________________________________________________________
Conv3d               2 x 64 x 12 x 8 x 8  73,856     True      
________________________________________________________________
Chomp1d              2 x 64 x 10 x 8 x 8  0          False     
________________________________________________________________
ReLU                 2 x 64 x 10 x 8 x 8  0          False     
________________________________________________________________
Dropout              2 x 64 x 10 x 8 x 8  0          False     
________________________________________________________________
Conv3d               2 x 64 x 12 x 8 x 8  73,856     True      
________________________________________________________________
Chomp1d              2 x 64 x 10 x 8 x 8  0          False     
________________________________________________________________
ReLU                 2 x 64 x 10 x 8 x 8  0          False     
________________________________________________________________
Dropout              2 x 64 x 10 x 8 x 8  0          False     
________________________________________________________________
Conv3d               2 x 64 x 12 x 8 x 8  73,856     True      
________________________________________________________________
Chomp1d              2 x 64 x 10 x 8 x 8  0          False     
________________________________________________________________
ReLU                 2 x 64 x 10 x 8 x 8  0          False     
________________________________________________________________
Dropout              2 x 64 x 10 x 8 x 8  0          False     
________________________________________________________________
Conv3d               2 x 64 x 12 x 8 x 8  73,856     True      
________________________________________________________________
Chomp1d              2 x 64 x 10 x 8 x 8  0          False     
________________________________________________________________
ReLU                 2 x 64 x 10 x 8 x 8  0          False     
________________________________________________________________
Dropout              2 x 64 x 10 x 8 x 8  0          False     
________________________________________________________________
ReLU                 2 x 64 x 10 x 8 x 8  0          False     
________________________________________________________________
Conv2d               2 x 128 x 8 x 8      8,192      True      
________________________________________________________________
BatchNorm2d          2 x 128 x 8 x 8      256        True      
________________________________________________________________
ReLU                 2 x 128 x 8 x 8      0          False     
________________________________________________________________
PixelShuffle         2 x 32 x 16 x 16     0          False     
________________________________________________________________
Conv2d               2 x 32 x 16 x 16     18,432     True      
________________________________________________________________
BatchNorm2d          2 x 32 x 16 x 16     64         True      
________________________________________________________________
ReLU                 2 x 32 x 16 x 16     0          False     
________________________________________________________________
Conv2d               2 x 32 x 16 x 16     9,216      True      
________________________________________________________________
BatchNorm2d          2 x 32 x 16 x 16     64         True      
________________________________________________________________
ReLU                 2 x 32 x 16 x 16     0          False     
________________________________________________________________
BatchNorm2d          2 x 32 x 16 x 16     64         True      
________________________________________________________________
Conv3d               2 x 32 x 12 x 16 x   18,496     True      
________________________________________________________________
Chomp1d              2 x 32 x 10 x 16 x   0          False     
________________________________________________________________
ReLU                 2 x 32 x 10 x 16 x   0          False     
________________________________________________________________
Dropout              2 x 32 x 10 x 16 x   0          False     
________________________________________________________________
Conv3d               2 x 32 x 12 x 16 x   18,496     True      
________________________________________________________________
Chomp1d              2 x 32 x 10 x 16 x   0          False     
________________________________________________________________
ReLU                 2 x 32 x 10 x 16 x   0          False     
________________________________________________________________
Dropout              2 x 32 x 10 x 16 x   0          False     
________________________________________________________________
Conv3d               2 x 32 x 12 x 16 x   18,496     True      
________________________________________________________________
Chomp1d              2 x 32 x 10 x 16 x   0          False     
________________________________________________________________
ReLU                 2 x 32 x 10 x 16 x   0          False     
________________________________________________________________
Dropout              2 x 32 x 10 x 16 x   0          False     
________________________________________________________________
Conv3d               2 x 32 x 12 x 16 x   18,496     True      
________________________________________________________________
Chomp1d              2 x 32 x 10 x 16 x   0          False     
________________________________________________________________
ReLU                 2 x 32 x 10 x 16 x   0          False     
________________________________________________________________
Dropout              2 x 32 x 10 x 16 x   0          False     
________________________________________________________________
ReLU                 2 x 32 x 10 x 16 x   0          False     
________________________________________________________________
Conv2d               2 x 64 x 16 x 16     2,048      True      
________________________________________________________________
BatchNorm2d          2 x 64 x 16 x 16     128        True      
________________________________________________________________
ReLU                 2 x 64 x 16 x 16     0          False     
________________________________________________________________
PixelShuffle         2 x 16 x 32 x 32     0          False     
________________________________________________________________
Conv2d               2 x 16 x 32 x 32     4,608      True      
________________________________________________________________
BatchNorm2d          2 x 16 x 32 x 32     32         True      
________________________________________________________________
ReLU                 2 x 16 x 32 x 32     0          False     
________________________________________________________________
Conv2d               2 x 16 x 32 x 32     2,304      True      
________________________________________________________________
BatchNorm2d          2 x 16 x 32 x 32     32         True      
________________________________________________________________
ReLU                 2 x 16 x 32 x 32     0          False     
________________________________________________________________
BatchNorm2d          2 x 16 x 32 x 32     32         True      
________________________________________________________________
Conv3d               2 x 16 x 12 x 32 x   4,640      True      
________________________________________________________________
Chomp1d              2 x 16 x 10 x 32 x   0          False     
________________________________________________________________
ReLU                 2 x 16 x 10 x 32 x   0          False     
________________________________________________________________
Dropout              2 x 16 x 10 x 32 x   0          False     
________________________________________________________________
Conv3d               2 x 16 x 12 x 32 x   4,640      True      
________________________________________________________________
Chomp1d              2 x 16 x 10 x 32 x   0          False     
________________________________________________________________
ReLU                 2 x 16 x 10 x 32 x   0          False     
________________________________________________________________
Dropout              2 x 16 x 10 x 32 x   0          False     
________________________________________________________________
Conv3d               2 x 16 x 12 x 32 x   4,640      True      
________________________________________________________________
Chomp1d              2 x 16 x 10 x 32 x   0          False     
________________________________________________________________
ReLU                 2 x 16 x 10 x 32 x   0          False     
________________________________________________________________
Dropout              2 x 16 x 10 x 32 x   0          False     
________________________________________________________________
Conv3d               2 x 16 x 12 x 32 x   4,640      True      
________________________________________________________________
Chomp1d              2 x 16 x 10 x 32 x   0          False     
________________________________________________________________
ReLU                 2 x 16 x 10 x 32 x   0          False     
________________________________________________________________
Dropout              2 x 16 x 10 x 32 x   0          False     
________________________________________________________________
ReLU                 2 x 16 x 10 x 32 x   0          False     
________________________________________________________________
Conv2d               2 x 32 x 32 x 32     512        True      
________________________________________________________________
BatchNorm2d          2 x 32 x 32 x 32     64         True      
________________________________________________________________
ReLU                 2 x 32 x 32 x 32     0          False     
________________________________________________________________
PixelShuffle         2 x 8 x 64 x 64      0          False     
________________________________________________________________
Conv2d               2 x 1 x 64 x 64      72         True      
________________________________________________________________
BatchNorm2d          2 x 1 x 64 x 64      2          True      
________________________________________________________________
ReLU                 2 x 1 x 64 x 64      0          False     
________________________________________________________________
Conv2d               2 x 1 x 64 x 64      9          True      
________________________________________________________________
BatchNorm2d          2 x 1 x 64 x 64      2          True      
________________________________________________________________
ReLU                 2 x 1 x 64 x 64      0          False     
________________________________________________________________

Total params: 846,525
Total trainable params: 846,525
Total non-trainable params: 0
</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">stcn</span> <span class="o">=</span> <span class="n">StackUnstack</span><span class="p">(</span><span class="n">stcn</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">stcn</span><span class="p">([</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">128</span><span class="p">,</span><span class="mi">128</span><span class="p">)</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">7</span><span class="p">)])[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>torch.Size([2, 1, 128, 128])</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="SimpleTCN2" class="doc_header"><code>class</code> <code>SimpleTCN2</code><a href="https://github.com/tcapelle/moving_mnist/tree/master/moving_mnist/models/tcn.py#L159" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>SimpleTCN2</code>(<strong><code>n_in</code></strong>=<em><code>1</code></em>, <strong><code>ks</code></strong>=<em><code>3</code></em>, <strong><code>n_out</code></strong>=<em><code>1</code></em>, <strong><code>norm</code></strong>=<em><code>&lt;NormType.Batch: 1&gt;</code></em>, <strong><code>dilation</code></strong>=<em><code>2</code></em>, <strong><code>debug</code></strong>=<em><code>False</code></em>) :: <code>Module</code></p>
</blockquote>
<p>Simple TCN model</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">stcn</span> <span class="o">=</span> <span class="n">SimpleTCN2</span><span class="p">()</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">stcn</span><span class="o">.</span><span class="n">summary</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">)</span><span class="o">.</span><span class="n">cuda</span><span class="p">())</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>SimpleTCN2 (Input shape: [&#39;2 x 1 x 10 x 64 x 64&#39;])
================================================================
Layer (type)         Output Shape         Param #    Trainable 
================================================================
AddCoords            2 x 4 x 64 x 64      0          False     
________________________________________________________________
Conv2d               2 x 8 x 64 x 64      40         True      
________________________________________________________________
Conv2d               2 x 16 x 64 x 64     1,152      True      
________________________________________________________________
BatchNorm2d          2 x 16 x 64 x 64     32         True      
________________________________________________________________
ReLU                 2 x 16 x 64 x 64     0          False     
________________________________________________________________
Conv3d               2 x 16 x 14 x 64 x   6,944      True      
________________________________________________________________
Chomp1d              2 x 16 x 10 x 64 x   0          False     
________________________________________________________________
ReLU                 2 x 16 x 10 x 64 x   0          False     
________________________________________________________________
Dropout              2 x 16 x 10 x 64 x   0          False     
________________________________________________________________
Conv3d               2 x 16 x 14 x 64 x   6,944      True      
________________________________________________________________
Chomp1d              2 x 16 x 10 x 64 x   0          False     
________________________________________________________________
ReLU                 2 x 16 x 10 x 64 x   0          False     
________________________________________________________________
Dropout              2 x 16 x 10 x 64 x   0          False     
________________________________________________________________
Conv3d               2 x 16 x 14 x 64 x   6,944      True      
________________________________________________________________
Chomp1d              2 x 16 x 10 x 64 x   0          False     
________________________________________________________________
ReLU                 2 x 16 x 10 x 64 x   0          False     
________________________________________________________________
Dropout              2 x 16 x 10 x 64 x   0          False     
________________________________________________________________
Conv3d               2 x 16 x 14 x 64 x   6,944      True      
________________________________________________________________
Chomp1d              2 x 16 x 10 x 64 x   0          False     
________________________________________________________________
ReLU                 2 x 16 x 10 x 64 x   0          False     
________________________________________________________________
Dropout              2 x 16 x 10 x 64 x   0          False     
________________________________________________________________
ReLU                 2 x 16 x 10 x 64 x   0          False     
________________________________________________________________
Conv2d               2 x 32 x 64 x 64     4,608      True      
________________________________________________________________
BatchNorm2d          2 x 32 x 64 x 64     64         True      
________________________________________________________________
ReLU                 2 x 32 x 64 x 64     0          False     
________________________________________________________________
Conv3d               2 x 32 x 14 x 64 x   27,712     True      
________________________________________________________________
Chomp1d              2 x 32 x 10 x 64 x   0          False     
________________________________________________________________
ReLU                 2 x 32 x 10 x 64 x   0          False     
________________________________________________________________
Dropout              2 x 32 x 10 x 64 x   0          False     
________________________________________________________________
Conv3d               2 x 32 x 14 x 64 x   27,712     True      
________________________________________________________________
Chomp1d              2 x 32 x 10 x 64 x   0          False     
________________________________________________________________
ReLU                 2 x 32 x 10 x 64 x   0          False     
________________________________________________________________
Dropout              2 x 32 x 10 x 64 x   0          False     
________________________________________________________________
Conv3d               2 x 32 x 14 x 64 x   27,712     True      
________________________________________________________________
Chomp1d              2 x 32 x 10 x 64 x   0          False     
________________________________________________________________
ReLU                 2 x 32 x 10 x 64 x   0          False     
________________________________________________________________
Dropout              2 x 32 x 10 x 64 x   0          False     
________________________________________________________________
Conv3d               2 x 32 x 14 x 64 x   27,712     True      
________________________________________________________________
Chomp1d              2 x 32 x 10 x 64 x   0          False     
________________________________________________________________
ReLU                 2 x 32 x 10 x 64 x   0          False     
________________________________________________________________
Dropout              2 x 32 x 10 x 64 x   0          False     
________________________________________________________________
ReLU                 2 x 32 x 10 x 64 x   0          False     
________________________________________________________________
Conv2d               2 x 64 x 64 x 64     18,432     True      
________________________________________________________________
BatchNorm2d          2 x 64 x 64 x 64     128        True      
________________________________________________________________
ReLU                 2 x 64 x 64 x 64     0          False     
________________________________________________________________
Conv3d               2 x 64 x 14 x 64 x   110,720    True      
________________________________________________________________
Chomp1d              2 x 64 x 10 x 64 x   0          False     
________________________________________________________________
ReLU                 2 x 64 x 10 x 64 x   0          False     
________________________________________________________________
Dropout              2 x 64 x 10 x 64 x   0          False     
________________________________________________________________
Conv3d               2 x 64 x 14 x 64 x   110,720    True      
________________________________________________________________
Chomp1d              2 x 64 x 10 x 64 x   0          False     
________________________________________________________________
ReLU                 2 x 64 x 10 x 64 x   0          False     
________________________________________________________________
Dropout              2 x 64 x 10 x 64 x   0          False     
________________________________________________________________
Conv3d               2 x 64 x 14 x 64 x   110,720    True      
________________________________________________________________
Chomp1d              2 x 64 x 10 x 64 x   0          False     
________________________________________________________________
ReLU                 2 x 64 x 10 x 64 x   0          False     
________________________________________________________________
Dropout              2 x 64 x 10 x 64 x   0          False     
________________________________________________________________
Conv3d               2 x 64 x 14 x 64 x   110,720    True      
________________________________________________________________
Chomp1d              2 x 64 x 10 x 64 x   0          False     
________________________________________________________________
ReLU                 2 x 64 x 10 x 64 x   0          False     
________________________________________________________________
Dropout              2 x 64 x 10 x 64 x   0          False     
________________________________________________________________
ReLU                 2 x 64 x 10 x 64 x   0          False     
________________________________________________________________
Conv3d               2 x 64 x 14 x 64 x   110,720    True      
________________________________________________________________
Chomp1d              2 x 64 x 10 x 64 x   0          False     
________________________________________________________________
ReLU                 2 x 64 x 10 x 64 x   0          False     
________________________________________________________________
Dropout              2 x 64 x 10 x 64 x   0          False     
________________________________________________________________
Conv3d               2 x 64 x 14 x 64 x   110,720    True      
________________________________________________________________
Chomp1d              2 x 64 x 10 x 64 x   0          False     
________________________________________________________________
ReLU                 2 x 64 x 10 x 64 x   0          False     
________________________________________________________________
Dropout              2 x 64 x 10 x 64 x   0          False     
________________________________________________________________
Conv3d               2 x 64 x 14 x 64 x   110,720    True      
________________________________________________________________
Chomp1d              2 x 64 x 10 x 64 x   0          False     
________________________________________________________________
ReLU                 2 x 64 x 10 x 64 x   0          False     
________________________________________________________________
Dropout              2 x 64 x 10 x 64 x   0          False     
________________________________________________________________
Conv3d               2 x 64 x 14 x 64 x   110,720    True      
________________________________________________________________
Chomp1d              2 x 64 x 10 x 64 x   0          False     
________________________________________________________________
ReLU                 2 x 64 x 10 x 64 x   0          False     
________________________________________________________________
Dropout              2 x 64 x 10 x 64 x   0          False     
________________________________________________________________
ReLU                 2 x 64 x 10 x 64 x   0          False     
________________________________________________________________
Conv2d               2 x 32 x 64 x 64     18,432     True      
________________________________________________________________
BatchNorm2d          2 x 32 x 64 x 64     64         True      
________________________________________________________________
ReLU                 2 x 32 x 64 x 64     0          False     
________________________________________________________________
Conv3d               2 x 32 x 14 x 64 x   27,712     True      
________________________________________________________________
Chomp1d              2 x 32 x 10 x 64 x   0          False     
________________________________________________________________
ReLU                 2 x 32 x 10 x 64 x   0          False     
________________________________________________________________
Dropout              2 x 32 x 10 x 64 x   0          False     
________________________________________________________________
Conv3d               2 x 32 x 14 x 64 x   27,712     True      
________________________________________________________________
Chomp1d              2 x 32 x 10 x 64 x   0          False     
________________________________________________________________
ReLU                 2 x 32 x 10 x 64 x   0          False     
________________________________________________________________
Dropout              2 x 32 x 10 x 64 x   0          False     
________________________________________________________________
Conv3d               2 x 32 x 14 x 64 x   27,712     True      
________________________________________________________________
Chomp1d              2 x 32 x 10 x 64 x   0          False     
________________________________________________________________
ReLU                 2 x 32 x 10 x 64 x   0          False     
________________________________________________________________
Dropout              2 x 32 x 10 x 64 x   0          False     
________________________________________________________________
Conv3d               2 x 32 x 14 x 64 x   27,712     True      
________________________________________________________________
Chomp1d              2 x 32 x 10 x 64 x   0          False     
________________________________________________________________
ReLU                 2 x 32 x 10 x 64 x   0          False     
________________________________________________________________
Dropout              2 x 32 x 10 x 64 x   0          False     
________________________________________________________________
ReLU                 2 x 32 x 10 x 64 x   0          False     
________________________________________________________________
Conv2d               2 x 16 x 64 x 64     4,608      True      
________________________________________________________________
BatchNorm2d          2 x 16 x 64 x 64     32         True      
________________________________________________________________
ReLU                 2 x 16 x 64 x 64     0          False     
________________________________________________________________
Conv3d               2 x 16 x 14 x 64 x   6,944      True      
________________________________________________________________
Chomp1d              2 x 16 x 10 x 64 x   0          False     
________________________________________________________________
ReLU                 2 x 16 x 10 x 64 x   0          False     
________________________________________________________________
Dropout              2 x 16 x 10 x 64 x   0          False     
________________________________________________________________
Conv3d               2 x 16 x 14 x 64 x   6,944      True      
________________________________________________________________
Chomp1d              2 x 16 x 10 x 64 x   0          False     
________________________________________________________________
ReLU                 2 x 16 x 10 x 64 x   0          False     
________________________________________________________________
Dropout              2 x 16 x 10 x 64 x   0          False     
________________________________________________________________
Conv3d               2 x 16 x 14 x 64 x   6,944      True      
________________________________________________________________
Chomp1d              2 x 16 x 10 x 64 x   0          False     
________________________________________________________________
ReLU                 2 x 16 x 10 x 64 x   0          False     
________________________________________________________________
Dropout              2 x 16 x 10 x 64 x   0          False     
________________________________________________________________
Conv3d               2 x 16 x 14 x 64 x   6,944      True      
________________________________________________________________
Chomp1d              2 x 16 x 10 x 64 x   0          False     
________________________________________________________________
ReLU                 2 x 16 x 10 x 64 x   0          False     
________________________________________________________________
Dropout              2 x 16 x 10 x 64 x   0          False     
________________________________________________________________
ReLU                 2 x 16 x 10 x 64 x   0          False     
________________________________________________________________
Conv2d               2 x 1 x 64 x 64      144        True      
________________________________________________________________
BatchNorm2d          2 x 1 x 64 x 64      2          True      
________________________________________________________________
ReLU                 2 x 1 x 64 x 64      0          False     
________________________________________________________________

Total params: 1,210,746
Total trainable params: 1,210,746
Total non-trainable params: 0
</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

</div>
 

