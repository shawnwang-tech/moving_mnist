{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp models.phy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PhyDNet\n",
    "> ConvLSTM + PhyCell\n",
    "https://github.com/vincent-leguen/PhyDNet/blob/master/models/models.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai.vision.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quadro RTX 8000\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    torch.cuda.set_device(0)\n",
    "    print(torch.cuda.get_device_name())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The PhyCell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will refactor this to not make the hidden state as a class attribute. We can also make use of some fastai magic, like `one_param` (to be sure to be on the same device as the model params) and `store_attr()` to save our class attributes.\n",
    "![phycell](images/phycell.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class PhyCell_Cell(Module):\n",
    "    def __init__(self, ch_in, hidden_dim, ks=3, bias=True):\n",
    "        store_attr()\n",
    "        padding = ks // 2\n",
    "        bias = bias\n",
    "        self.f = nn.Sequential(\n",
    "                 nn.BatchNorm2d(ch_in),   \n",
    "                 nn.Conv2d(ch_in, hidden_dim, ks, padding=padding),\n",
    "                 nn.Conv2d(hidden_dim, ch_in, kernel_size=(1,1)))\n",
    "\n",
    "        self.convgate = nn.Conv2d(2*ch_in,\n",
    "                                  ch_in,\n",
    "                                  kernel_size=(3,3),\n",
    "                                  padding=(1,1), \n",
    "                                  bias=bias)\n",
    "\n",
    "    def forward(self, x, hidden=None): \n",
    "        \"x ~[batch_size, hidden_dim, height, width]\"  \n",
    "        if hidden is None: hidden = self.init_hidden(x)\n",
    "        hidden_tilde = hidden + self.f(hidden)\n",
    "        combined = torch.cat([x, hidden_tilde], dim=1)\n",
    "        combined_conv = self.convgate(combined)\n",
    "        K = torch.sigmoid(combined_conv)\n",
    "        next_hidden = hidden_tilde + K * (x - hidden_tilde)\n",
    "        return next_hidden\n",
    "    \n",
    "    def init_hidden(self, x):\n",
    "        bs, ch, h, w = x.shape\n",
    "        return one_param(self).new_zeros(bs, ch, h, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PhyCell_Cell(\n",
       "  (f): Sequential(\n",
       "    (0): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (convgate): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_cell = PhyCell_Cell(16, 32, 3).cuda()\n",
    "p_cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 16, 12, 12])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = p_cell(torch.rand(64,16,12,12).cuda())\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0899, device='cuda:0', grad_fn=<MseLossBackward>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_loss = MSELossFlat()\n",
    "loss = mse_loss(out, torch.zeros_like(out))\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0899, device='cuda:0', grad_fn=<MseLossBackward>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class PhyCell(Module):\n",
    "    def __init__(self, ch_in, hidden_dims, ks, n_layers):\n",
    "        store_attr() \n",
    "        self.cell_list = nn.ModuleList()\n",
    "        for i in range(self.n_layers):\n",
    "            self.cell_list.append(PhyCell_Cell(ch_in=ch_in,\n",
    "                                               hidden_dim=hidden_dims[i],\n",
    "                                               ks=ks))                                     \n",
    "       \n",
    "    def forward(self, x, hidden=None): \n",
    "        \"x ~ [batch_size, seq_len, channels, width, height]\"    \n",
    "        assert x.shape[2] == self.ch_in, \"Input tensor has different channels dim than Cell\"\n",
    "        if hidden is None: hidden = self.init_hidden(x)\n",
    "        cur_layer_input = torch.unbind(x, dim=1)\n",
    "        seq_len = len(cur_layer_input)\n",
    "        last_state_list = []\n",
    "        \n",
    "        for cell, h in zip(self.cell_list, hidden):\n",
    "            output_inner = []\n",
    "            for inp in cur_layer_input:\n",
    "                hid = cell(inp, h)\n",
    "                output_inner.append(hid)\n",
    "            cur_layer_input = output_inner\n",
    "            last_state_list.append(h)\n",
    "            \n",
    "        layer_output = torch.stack(output_inner, dim=1)\n",
    "        last_states = torch.stack(last_state_list, dim=0)\n",
    "        return layer_output, last_states\n",
    "    \n",
    "    def init_hidden(self, x):\n",
    "        assert len(x.shape)==5, \"input shape must be [bs, seq_len, ch, w, h]\"\n",
    "        hid = [] \n",
    "        for l in self.cell_list:\n",
    "            hid.append(l.init_hidden(x[:,0, ...]))\n",
    "        return hid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phy = PhyCell(16, [49], 7, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out, states = phy(torch.rand(8,10,16,6,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 10, 16, 6, 6]), torch.Size([1, 8, 16, 6, 6]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape, states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 16, 6, 6])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states[-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0910, grad_fn=<MseLossBackward>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_loss = MSELossFlat()\n",
    "loss = mse_loss(out, torch.zeros_like(out))\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0910, grad_fn=<MseLossBackward>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_data.ipynb.\n",
      "Converted 01_models.conv_rnn.ipynb.\n",
      "Converted 02_models.dcn.ipynb.\n",
      "Converted 02_models.transformer.ipynb.\n",
      "Converted 02_tcn.ipynb.\n",
      "Converted 03_phy.ipynb.\n",
      "Converted 04_seq2seq.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
